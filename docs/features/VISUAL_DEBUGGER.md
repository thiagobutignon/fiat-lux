# Visual Debugger

**Innovation #24: "Deixar de Ser Caixa Preta" (Stop Being Black Box)**

Transform the AGI from an opaque "black box" into a transparent "glass box" where every decision, concept activation, and reasoning path is fully visible and explainable.

## Overview

The Visual Debugger provides complete visibility into the AGI's reasoning process through four integrated layers:

1. **Explanation Layer**: Decision paths, confidence flows, concept activation
2. **Concept Attribution**: Track which concepts contributed to each decision
3. **Counterfactual Reasoning**: "What if we didn't have X?"
4. **Interactive Visualizations**: Agent graphs, timelines, heatmaps

## Key Features

### 1. Explanation Layer

Track the complete reasoning flow through the system:

```typescript
import { createVisualDebugger } from './core/visual-debugger';

const vDebugger = createVisualDebugger();
vDebugger.startSession('How to save money?');

// Track decisions
vDebugger.trackDecision({
  id: 'decision-1',
  agent: 'financial-agent',
  timestamp: new Date(),
  input: 'How to save money?',
  output: 'Create a budget and track expenses',
  confidence: 0.85,
  reasoning: 'Based on financial planning principles',
  concepts_used: ['budgeting', 'expense-tracking']
});

// Track confidence flow
vDebugger.trackConfidenceFlow({
  node_id: 'decision-1',
  confidence_in: 0.6,
  confidence_out: 0.85,
  confidence_delta: 0.25,
  factors: [
    { concept: 'budgeting', weight: 0.7, contribution: 0.18 },
    { concept: 'expense-tracking', weight: 0.3, contribution: 0.07 }
  ]
});

// Track concept activation
vDebugger.trackConceptActivation({
  concept: 'compound-interest',
  slice: 'financial/savings',
  activation_strength: 0.9,
  timestamp: new Date(),
  context: 'Calculating long-term savings',
  contribution_to_output: 0.8
});
```

### 2. Concept Attribution

See exactly which concepts from which knowledge slices contributed to each decision:

```typescript
const snapshot = vDebugger.captureSnapshot('How to save money?');

// Get top influencers
const topInfluencers = vDebugger.getTopInfluencers(snapshot, 5);

for (const concept of topInfluencers) {
  console.log(`${concept.concept}: ${concept.contribution_to_output * 100}%`);
  console.log(`  From: ${concept.slice}`);
  console.log(`  Context: ${concept.context}`);
}

// Output:
// compound-interest: 80.0%
//   From: financial/savings
//   Context: Calculating long-term savings
//
// budgeting: 70.0%
//   From: financial/planning
//   Context: Budget allocation strategy
```

### 3. Counterfactual Reasoning

Understand causal relationships by asking "What if we didn't have X?":

```typescript
// What if we didn't have the biology agent?
const counterfactual = vDebugger.analyzeCounterfactual(
  snapshot,
  'biology-agent',
  'agent'
);

console.log(`Impact Score: ${counterfactual.impact_score * 100}%`);
console.log(`Confidence Change: ${counterfactual.confidence_change * 100}%`);
console.log(counterfactual.explanation);

// Output:
// Impact Score: 45.0%
// Confidence Change: -15.0%
// Removing agent "biology-agent" would have a significant impact on
// the reasoning chain. Average confidence would have decreased by 15.0%.
```

You can analyze the impact of removing:
- **Agents**: What if a specific agent wasn't invoked?
- **Concepts**: What if a specific concept wasn't available?
- **Slices**: What if an entire knowledge slice was missing?

### 4. Interactive Visualizations

#### Agent Collaboration Graph

```typescript
const visualization = vDebugger.visualizeAgentGraph(snapshot.agent_graph);
console.log(visualization);
```

Output:
```
ğŸ“Š Agent Collaboration Graph
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”µ Agents:
  meta-agent            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 85.0%
    Invocations: 2, Concepts: 3
  financial-agent       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 90.0%
    Invocations: 1, Concepts: 5
  biology-agent         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 82.0%
    Invocations: 1, Concepts: 3

ğŸ”— Interactions:
  meta-agent â”€â”€â”€â”€â”€â”€â”€> financial-agent (1x, 90.0%)
  meta-agent â”€â”€â”€â”€â”€â”€â”€> biology-agent (1x, 82.0%)
```

#### Decision Timeline

```typescript
const timeline = vDebugger.visualizeTimeline(snapshot.timeline);
console.log(timeline);
```

Output:
```
ğŸ“… Decision Timeline
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

19:45:01 ğŸ¤– meta-agent processed: "How to save money?"...
19:45:02 ğŸ’¡ Concept "query-decomposition" activated (strength: 90.0%)
19:45:03 ğŸ¤– financial-agent processed: "Analyze savings strategies"...
19:45:03 ğŸ’¡ Concept "compound-interest" activated (strength: 95.0%)
19:45:04 ğŸ“Š Confidence increased to 90.0%
19:45:05 ğŸ¤– biology-agent processed: "Analyze budget as system"...
19:45:05 ğŸ’¡ Concept "homeostasis" activated (strength: 88.0%)
```

#### Concept Activation Heatmap

```typescript
const heatmap = vDebugger.visualizeConceptHeatmap(snapshot.explanation.concept_activation);
console.log(heatmap);
```

Output:
```
ğŸ”¥ Concept Activation Heatmap
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

compound-interest         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  Strength: 95.0%, Contribution: 80.0%
  From: financial/savings

homeostasis               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  Strength: 88.0%, Contribution: 75.0%
  From: biology/regulation

leverage-points           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  Strength: 92.0%, Contribution: 85.0%
  From: systems/thinking
```

### 5. Full Report Export

Export a complete debugging report for regulatory compliance or analysis:

```typescript
const report = vDebugger.exportReport(snapshot);
console.log(report);

// Or save to file
fs.writeFileSync('debug-report.txt', report);
```

The report includes:
- Query and timestamp
- Agent collaboration graph
- Decision timeline
- Concept activation heatmap
- Top 5 most influential concepts
- Alternative paths considered
- Complete decision path
- Confidence flow analysis

## Use Cases

### 1. Developer Debugging

**Question**: "Why did the system give this answer?"

**Answer**: View the complete decision path, see which agents were invoked, which concepts were activated, and how confidence evolved.

### 2. Regulatory Auditing

**Question**: "Which data influenced this financial advice?"

**Answer**: Export full audit trail showing exactly which knowledge slices and concepts contributed to the decision, with confidence scores and timestamps.

### 3. Pattern Discovery

**Question**: "What patterns emerge in cross-domain reasoning?"

**Answer**: Analyze multiple snapshots to discover recurring patterns, frequently activated concepts, and common agent collaboration patterns.

### 4. User Trust

**Question**: "How did you reach this conclusion?"

**Answer**: Provide step-by-step explanation showing the reasoning chain from query to answer, with concept attribution and confidence scores.

## Performance

- **Overhead**: <1% of execution time
- **Memory**: ~200 bytes per trace
- **Latency**: <1ms per tracked event
- **Storage**: ~10KB per session snapshot

## API Reference

### Core Methods

#### `startSession(query: string)`
Start tracking a new query session.

#### `trackDecision(decision: DecisionNode)`
Track an agent decision/invocation.

#### `trackConfidenceFlow(flow: ConfidenceFlow)`
Track how confidence changes through the system.

#### `trackConceptActivation(activation: ConceptActivation)`
Track when a concept is activated and its contribution.

#### `trackAlternativePath(path: AlternativePath)`
Track an alternative reasoning path that was considered but not taken.

#### `captureSnapshot(query: string): VisualDebuggerSnapshot`
Capture a complete snapshot of the current session.

### Analysis Methods

#### `getTopInfluencers(snapshot, n: number): ConceptActivation[]`
Get the N most influential concepts in a snapshot.

#### `getCriticalPath(snapshot): DecisionNode[]`
Get the critical decision path (high-confidence decisions â‰¥70%).

#### `analyzeCounterfactual(snapshot, element: string, type: 'slice' | 'concept' | 'agent'): CounterfactualAnalysis`
Analyze the impact of removing an element.

### Visualization Methods

#### `visualizeAgentGraph(graph: AgentGraph): string`
Generate ASCII visualization of agent collaboration.

#### `visualizeTimeline(timeline: TimelineEvent[]): string`
Generate ASCII visualization of decision timeline.

#### `visualizeConceptHeatmap(activations: ConceptActivation[]): string`
Generate ASCII heatmap of concept activations.

#### `exportReport(snapshot: VisualDebuggerSnapshot): string`
Export complete debugging report.

### State Management

#### `getSnapshots(): VisualDebuggerSnapshot[]`
Get all captured snapshots.

#### `clearSnapshots()`
Clear all snapshots from memory.

## Integration with Meta-Agent

The Visual Debugger can be integrated directly into the Meta-Agent:

```typescript
import { MetaAgent } from './core/meta-agent';
import { createVisualDebugger } from './core/visual-debugger';

const metaAgent = new MetaAgent(apiKey);
const vDebugger = createVisualDebugger();

// Wrap meta-agent processing with debugging
vDebugger.startSession(query);

const result = await metaAgent.process(query);

// Track meta-agent decisions
vDebugger.trackDecision({
  id: 'meta-1',
  agent: 'meta-agent',
  timestamp: new Date(),
  input: query,
  output: result.final_answer,
  confidence: result.confidence,
  reasoning: result.reasoning,
  concepts_used: result.concepts_used
});

// Capture snapshot
const snapshot = vDebugger.captureSnapshot(query);
const report = vDebugger.exportReport(snapshot);
```

## Running the Demo

```bash
npm run agi:visual-debugger
```

The demo simulates a complete query session showing:
- Multi-agent collaboration (meta-agent, financial-agent, biology-agent, systems-agent)
- Concept activation from multiple knowledge slices
- Confidence flow through the system
- Alternative paths that were considered
- Counterfactual analysis
- Full visualization and report export

## Philosophical Implications

The Visual Debugger represents a fundamental shift in AGI interpretability:

### From Black Box to Glass Box

**Traditional AGI**: "Here's the answer" (no explanation)

**With Visual Debugger**: "Here's the answer, here's exactly how I reached it, here's what I considered and rejected, here's what would change if we didn't have X"

### Epistemic Honesty

The system doesn't just provide answers - it provides **justification**:
- Which knowledge was used
- How confident it is in each step
- What alternative paths it considered
- What the causal relationships are

### Regulatory Compliance

Full auditability enables deployment in regulated industries:
- Financial services: "Which data influenced this investment advice?"
- Healthcare: "Which medical knowledge contributed to this diagnosis?"
- Legal: "Which precedents were considered in this analysis?"

### Scientific Reproducibility

Complete decision traces enable:
- Bug reproduction: "This query failed, let's see where"
- A/B testing: "Did the new slice improve reasoning?"
- Performance analysis: "Which agents/concepts are most valuable?"

## Testing

Run the comprehensive test suite:

```bash
npx vitest run src/agi-recursive/tests/visual-debugger.test.ts
```

23 tests covering:
- Session management
- Decision tracking
- Confidence flow tracking
- Concept activation tracking
- Alternative paths tracking
- Top influencers analysis
- Critical path extraction
- Counterfactual reasoning
- All visualization methods
- Report export

## Future Enhancements

Potential extensions:

1. **Interactive Web UI**: Real-time visualization in browser
2. **Attention Flow Diagrams**: Sankey diagrams showing information flow
3. **Concept Network Graphs**: Network visualization of concept relationships
4. **Temporal Analysis**: Track how reasoning patterns evolve over time
5. **Comparative Analysis**: Compare reasoning across multiple queries
6. **Machine Learning**: Learn to predict influential concepts
7. **Natural Language Explanations**: Convert traces to human-readable explanations

## Conclusion

The Visual Debugger transforms the AGI from an inscrutable black box into a transparent, auditable, and understandable system. Every decision is traceable, every concept is attributed, and every causal relationship is quantifiable.

**Innovation #24: "Deixar de Ser Caixa Preta" (Stop Being Black Box)**

Built with TDD, 23 passing tests, <1% performance overhead. ğŸ”âœ¨
