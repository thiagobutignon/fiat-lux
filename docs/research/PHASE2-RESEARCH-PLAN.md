# Phase 2: Activation Flow Tracing & Intervention
## Research Plan & Methodology

**Start Date**: 2025-10-08
**Status**: ğŸš€ In Progress
**Dependencies**: Phase 1 Complete âœ…

---

## ğŸ¯ Objectives

### Primary Goals
1. **Validate Phase 1 hypotheses** with runtime activation data
2. **Trace information flow** during actual hallucination events
3. **Measure attention patterns** in layers 0 vs 31 for hallucination-prone prompts
4. **Test interventions** to reduce hallucinations

### Success Criteria
- âœ… Capture activations for â‰¥20 hallucination events
- âœ… Quantify attention strength difference layer 0 vs 31
- âœ… Demonstrate â‰¥30% hallucination reduction with intervention
- âœ… Validate at least 3 of 5 Phase 1 hypotheses

---

## ğŸ“‹ Task Breakdown

### **Task 2.1: Baseline Activation Capture** [3-4 hours]
**Goal**: Capture activations during inference for hallucination-prone prompts

**Subtasks**:
1. âœ… Create hallucination benchmark dataset (10-20 prompts)
2. Build activation capture framework (llama.cpp integration)
3. Capture layer-by-layer activations:
   - Attention weights (QÂ·K scores)
   - Value activations (post-attention)
   - FFN gate activations
   - Layer norm outputs
4. Store activation traces to JSON for analysis

**Outputs**:
- `hallucination-benchmark.json` (prompts + expected behaviors)
- `activation-tracer.ts` (capture framework)
- `research-output/phase2/activations/baseline-*.json` (activation data)

---

### **Task 2.2: Attention Pattern Analysis** [2-3 hours]
**Goal**: Quantify attention strength across layers during hallucinations

**Subtasks**:
1. Extract attention weights from captured activations
2. Compute attention entropy (measure of focus vs diffusion)
3. Compare layer 0 vs layer 31:
   - Attention to input tokens
   - Attention to recent context
   - Self-attention strength
4. Identify "context dropout" points (where attention weakens)

**Outputs**:
- `phase2-task2.1-attention-analysis.ts` (analysis script)
- Attention heatmaps (layer x token)
- Quantitative metrics (entropy, focus scores)

**Hypothesis Validation**:
- âœ… **H1**: Layer 31 attention is significantly weaker than layer 0
- âœ… **H2**: Attention to input context decreases in late layers

---

### **Task 2.3: FFN vs Attention Balance** [2 hours]
**Goal**: Measure FFN activation strength vs attention during hallucinations

**Subtasks**:
1. Extract FFN gate activations from traces
2. Compute FFN/Attention activation ratio per layer
3. Identify "crossover point" (where FFN overtakes attention)
4. Correlate FFN dominance with hallucination events

**Outputs**:
- FFN vs Attention activation plots
- Crossover layer identification
- Correlation analysis (FFN strength vs hallucination rate)

**Hypothesis Validation**:
- âœ… **H3**: FFN activations are 2x stronger than attention in layer 31
- âœ… **H4**: Crossover point occurs around layers 20-25

---

### **Task 2.4: Value Tensor Flow Analysis** [2 hours]
**Goal**: Trace how information flows through value tensors

**Subtasks**:
1. Measure value tensor activations (post-softmax)
2. Compute "information retention" (how much input context is preserved)
3. Identify layers with high value sparsity activation
4. Track "context drift" (semantic shift across layers)

**Outputs**:
- Value activation heatmaps
- Information retention curves
- Context drift analysis

**Hypothesis Validation**:
- âœ… **H5**: Value sparsity causes information loss in late layers
- âœ… **H6**: Layer 31 values are amplified but sparse

---

### **Task 2.5: Intervention Experiments** [4-6 hours]
**Goal**: Test if interventions reduce hallucinations

**Experiments**:

#### **Experiment A: Attention Boosting**
- **Method**: Artificially increase attention weights in layer 31
- **Implementation**: Multiply attention scores by scaling factor (1.5x, 2x)
- **Expected**: Stronger context verification â†’ fewer hallucinations

#### **Experiment B: FFN Suppression**
- **Method**: Reduce FFN gate activations in layer 31
- **Implementation**: Multiply gate outputs by dampening factor (0.5x, 0.7x)
- **Expected**: Less pattern-based generation â†’ more factual outputs

#### **Experiment C: Value Densification**
- **Method**: Force dense value activations (reduce sparsity)
- **Implementation**: Apply softmax temperature adjustment
- **Expected**: Better context preservation â†’ fewer errors

#### **Experiment D: Layer Norm Adjustment**
- **Method**: Reduce FFN norm scale in layer 31
- **Implementation**: Divide FFN norm output by 1.3 (reverse +30.7% boost)
- **Expected**: Less FFN amplification â†’ balanced attention-FFN

**Outputs**:
- Intervention scripts (one per experiment)
- Comparative hallucination rates (baseline vs intervention)
- Activation traces for intervened runs

**Success Metrics**:
- â‰¥30% hallucination reduction in at least one experiment
- Maintained output quality (fluency, coherence)

---

## ğŸ§ª Hallucination Benchmark Dataset

### Categories

#### **Category 1: Factual Recall** (5 prompts)
Prompts that require retrieving specific facts from context.

**Example**:
```
Prompt: "Based on the following text, who discovered penicillin?
Text: Alexander Fleming discovered penicillin in 1928 by accident."

Expected: Alexander Fleming
Hallucination Risk: Model may confuse with other scientists (Marie Curie, etc.)
```

#### **Category 2: Temporal Reasoning** (5 prompts)
Prompts requiring understanding of time sequences.

**Example**:
```
Prompt: "Given the timeline: Event A (1990), Event B (1995), Event C (1985).
Which event happened first?"

Expected: Event C (1985)
Hallucination Risk: Model may generate plausible but incorrect ordering
```

#### **Category 3: Numerical Accuracy** (5 prompts)
Prompts with specific numbers that must be preserved.

**Example**:
```
Prompt: "If a product costs $49.99 and there's a 20% discount, what's the final price?"

Expected: $39.99 (or $40)
Hallucination Risk: Model may generate plausible but wrong calculations
```

#### **Category 4: Logical Consistency** (5 prompts)
Prompts that require maintaining logical coherence.

**Example**:
```
Prompt: "All birds can fly. Penguins are birds. Can penguins fly?"

Expected: No (contradiction with premise)
Hallucination Risk: Model may ignore contradiction and say "yes"
```

---

## ğŸ› ï¸ Technical Implementation

### Activation Capture Strategy

**Challenge**: llama.cpp doesn't expose internal activations by default

**Solutions**:
1. **Option A**: Modify llama.cpp source to export activations
   - âœ… Most accurate
   - âŒ Requires C++ modifications
   - âŒ Harder to maintain across llama.cpp updates

2. **Option B**: Use GGUF Python bindings with custom hooks
   - âœ… Easier to implement
   - âœ… Python ecosystem for analysis
   - âš ï¸ May be slower

3. **Option C**: Build TypeScript wrapper around llama.cpp CLI
   - âœ… Stays in our stack
   - âš ï¸ Limited to what llama.cpp exposes
   - âŒ May not have activation access

**Recommendation**: Start with **Option B** (Python bindings + hooks) for speed, fall back to Option A if needed.

---

### Intervention Implementation Strategy

**Challenge**: Modifying activations during inference

**Approach**:
1. **Load model** into memory
2. **Register hooks** at target layers (layer 31)
3. **Intercept activations** (attention scores, FFN gates)
4. **Apply transformations** (boost, suppress, etc.)
5. **Continue inference** with modified activations
6. **Compare outputs** vs baseline

**Libraries**:
- **llama-cpp-python**: Python bindings for llama.cpp
- **PyTorch** (optional): If we need to load GGUF â†’ PyTorch for intervention
- **Transformers** (optional): Hugging Face for easier layer access

---

## ğŸ“Š Expected Outcomes

### If Hypotheses Correct:

| Hypothesis | Expected Evidence | Validation Method |
|------------|------------------|-------------------|
| H1: Weak Attention (L31) | Attention entropy â†‘, focus score â†“ | Measure attention weights |
| H2: FFN Dominance (L31) | FFN/Attn ratio â‰ˆ 2.0 | Compare activations |
| H3: Value Sparsity Loss | Info retention â†“ 40-60% | Track value activations |
| H4: Attention Boost Helps | Hallucinations â†“ 30%+ | Intervention A results |
| H5: FFN Suppress Helps | Hallucinations â†“ 20-30% | Intervention B results |

### If Hypotheses Incorrect:

**Alternative Explanations to Investigate**:
- Training data quality (not architecture)
- Tokenization artifacts
- Quantization errors (Q4_K introduces hallucinations)
- Prompt engineering issues

---

## ğŸ“ˆ Milestones & Timeline

### Week 1: Setup & Baseline (Tasks 2.1-2.2)
- âœ… Day 1-2: Build activation capture framework
- âœ… Day 3-4: Capture baseline activations
- âœ… Day 5: Analyze attention patterns

### Week 2: Analysis & Intervention (Tasks 2.3-2.5)
- âœ… Day 6-7: FFN vs Attention analysis
- âœ… Day 8-9: Value flow analysis
- âœ… Day 10-12: Run intervention experiments
- âœ… Day 13-14: Consolidate findings

### Deliverables
- ğŸ“Š Activation dataset (20+ hallucination traces)
- ğŸ“ˆ Quantitative metrics (attention/FFN ratios, entropy, etc.)
- ğŸ§ª Intervention results (comparative hallucination rates)
- ğŸ“ Phase 2 research report (validates/refutes hypotheses)

---

## ğŸ”— Phase 1 â†’ Phase 2 Connection

### Phase 1 Findings â†’ Phase 2 Tests

| Phase 1 Discovery | Phase 2 Validation |
|------------------|-------------------|
| Q/Gate ratio = 0.50 (L31) | Measure FFN/Attn activation ratio |
| Value sparsity 2.79% | Track value activation sparsity |
| Value amplification +134% | Measure value magnitude changes |
| FFN Norm +30.7% | Compare norm outputs L0 vs L31 |
| Attention weakening | Plot attention entropy across layers |

### Key Question to Answer
**"Does the weight-based structural bias translate to runtime behavior bias during hallucinations?"**

If YES â†’ Architecture causes hallucinations (fix requires model redesign)
If NO â†’ Training/data causes hallucinations (fix requires better data)

---

## ğŸ¯ Success Definition

Phase 2 is successful if:
1. âœ… We **validate â‰¥3 of 5 hypotheses** from Phase 1
2. âœ… We **demonstrate causal link** between layer 31 patterns and hallucinations
3. âœ… We **reduce hallucinations by â‰¥30%** with at least one intervention
4. âœ… We **publish findings** that advance hallucination research

---

**Phase 2 Status**: ğŸš€ Starting Now!
**Next Task**: Build activation capture framework (Task 2.1)

Let's go! ğŸ”¬
